{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c74e7f2ba9345de8d2e4a235edeffbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bee8db59800840d3a82c94ea0f8f5ab9",
              "IPY_MODEL_003690d14a944274a8f345f22a82a774",
              "IPY_MODEL_e6dd645e4ee34f61b32c87c738bbd73e"
            ],
            "layout": "IPY_MODEL_fbd1ed5fab344825862d66164d615104"
          }
        },
        "bee8db59800840d3a82c94ea0f8f5ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec8464febb04c4f98540f3ef8f902a8",
            "placeholder": "​",
            "style": "IPY_MODEL_1256e58c8cc74deebc86a47d91799680",
            "value": "model.safetensors: 100%"
          }
        },
        "003690d14a944274a8f345f22a82a774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cafb0ac332714a52881c8bc2c71785fc",
            "max": 354400320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8a590c25df74af6b307f53a56b40da7",
            "value": 354400320
          }
        },
        "e6dd645e4ee34f61b32c87c738bbd73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5b9820830f64da48c94ad6a4f74d510",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ac8f52bf4d46adb85a37e8ccc27277",
            "value": " 354M/354M [00:05&lt;00:00, 59.0MB/s]"
          }
        },
        "fbd1ed5fab344825862d66164d615104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec8464febb04c4f98540f3ef8f902a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1256e58c8cc74deebc86a47d91799680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafb0ac332714a52881c8bc2c71785fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a590c25df74af6b307f53a56b40da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5b9820830f64da48c94ad6a4f74d510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ac8f52bf4d46adb85a37e8ccc27277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfqPRqnbg4QK",
        "outputId": "7d75d3e9-2078-42db-fa6b-f7c55053c201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\n",
            "Cloning into 'VMamba'...\n",
            "remote: Enumerating objects: 8910, done.\u001b[K\n",
            "remote: Counting objects: 100% (1398/1398), done.\u001b[K\n",
            "remote: Compressing objects: 100% (175/175), done.\u001b[K\n",
            "remote: Total 8910 (delta 1341), reused 1223 (delta 1223), pack-reused 7512 (from 2)\u001b[K\n",
            "Receiving objects: 100% (8910/8910), 34.84 MiB | 17.16 MiB/s, done.\n",
            "Resolving deltas: 100% (5492/5492), done.\n"
          ]
        }
      ],
      "source": [
        "# Gerekli kütüphaneler\n",
        "!pip install timm scikit-learn numpy pandas tqdm torch torchvision\n",
        "\n",
        "# VMamba reposunu klonla\n",
        "# Not: Bu adım, eğer Colab ortamında modeliniz yüklü değilse gereklidir.\n",
        "# VMamba_v10.pth modelini manuel olarak Drive'a yüklediyseniz bu satıra gerek kalmayabilir.\n",
        "!git clone https://github.com/MzeroMiko/VMamba.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Bu kısım sadece Colab'da çalışır\n",
        "try:\n",
        "    print(\"Google Drive'a bağlanılıyor...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Drive bağlantısı başarılı.\")\n",
        "\n",
        "    # Veri setinizin Google Drive'daki yolu\n",
        "    # Lütfen 'new_data' klasörünün doğru yolda olduğundan emin olun\n",
        "    DATA_DIR = '/content/drive/MyDrive/data_v1'\n",
        "\n",
        "except ImportError:\n",
        "    # Colab dışında çalışıyorsanız bu yol kullanılır\n",
        "    print(\"Colab ortamı algılanmadı. Yerel yollar kullanılıyor.\")\n",
        "    DATA_DIR = './data_v1'\n",
        "\n",
        "# Veri klasörünün varlığını kontrol et\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    raise FileNotFoundError(f\"Hata: '{DATA_DIR}' yolu bulunamadı. Lütfen Google Drive'daki veri klasörünün doğru konumda olduğundan emin olun.\")\n",
        "else:\n",
        "    print(f\"Veri klasörü başarıyla bulundu: {DATA_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IJcPUtVhAgE",
        "outputId": "2c270fa6-a273-41f1-8141-01302a80edf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive'a bağlanılıyor...\n",
            "Mounted at /content/drive\n",
            "Drive bağlantısı başarılı.\n",
            "Veri klasörü başarıyla bulundu: /content/drive/MyDrive/data_v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# --- YARDIMCI FONKSİYON: SÜRE FORMATLAMA ---\n",
        "\n",
        "def format_duration(seconds):\n",
        "    \"\"\"Saniye cinsinden süreyi (H saat, M dakika, S saniye) formatına dönüştürür.\n",
        "       İstenen HH saat, MM dakika, SS saniye formatı kullanılır.\"\"\"\n",
        "    seconds = int(round(seconds))\n",
        "    h = seconds // 3600\n",
        "    m = (seconds % 3600) // 60\n",
        "    s = seconds % 60\n",
        "    return f\"{h:02d} saat, {m:02d} dakika, {s:02d} saniye\"\n",
        "\n",
        "# --- YAPILANDIRMA VE YOL TANIMLARI ---\n",
        "\n",
        "# LÜTFEN KONTROL EDİN: Drive üzerindeki verilerinizin ana klasör yolu\n",
        "ROOT_DIR = '/content/drive/MyDrive/data_v1'\n",
        "# EĞİTİLMİŞ MODELLERİN KAYDEDİLECEĞİ KLASÖR YOLU\n",
        "DRIVE_MODEL_DIR = '/content/drive/MyDrive/vmamba_models'\n",
        "\n",
        "# SADECE TÜRKÇE (TR) İÇİN HARF LİSTESİ\n",
        "language_info = {\n",
        "    # Bu liste alt klasör isimlerinizle eşleşmelidir.\n",
        "    'TR': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z'],\n",
        "}\n",
        "ALL_LANG_CODES = ['TR']\n",
        "\n",
        "# Eğitim parametreleri\n",
        "NUM_EPOCHS = 50 # Colab'da GPU'da bile uzun sürebilir\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0001\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- MODEL VE VERİ SINIFLARI ---\n",
        "\n",
        "class CustomMambaClassifier(nn.Module):\n",
        "    \"\"\"VMamba'ya benzer şekilde çalışan, ConvNeXt tabanlı görüntü sınıflandırıcısı.\"\"\"\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(CustomMambaClassifier, self).__init__()\n",
        "        # Güçlü bir temel olarak ConvNeXt Base kullanılıyor.\n",
        "        self.backbone = timm.create_model('convnext_base', pretrained=pretrained, features_only=True)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.backbone.feature_info[-1]['num_chs'], self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Yalnızca son özellik haritası kullanılır\n",
        "        x = self.backbone(x)[-1]\n",
        "        x = self.avgpool(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "class SignLanguageDataset(Dataset):\n",
        "    \"\"\"İşaret dili görüntüleri için özel veri kümesi sınıfı.\"\"\"\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# --- VERİ HAZIRLAMA FONKSİYONU ---\n",
        "\n",
        "def prepare_lang_data(root_dir, lang_code, test_size=TEST_SIZE, random_state=RANDOM_STATE):\n",
        "    \"\"\"Sadece belirtilen dilin resimlerini toplar ve etiketler.\"\"\"\n",
        "    all_image_paths = []\n",
        "    all_labels = []\n",
        "\n",
        "    lang_path = os.path.join(root_dir, lang_code)\n",
        "    if not os.path.exists(lang_path):\n",
        "        print(f\"Uyarı: '{lang_code}' diline ait klasör bulunamadı. Bu dil atlanıyor.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    # Bu döngü, tek el resimlerini içeren klasörleri (örn: C) ve\n",
        "    # çift el resimlerini içeren klasörleri (örn: H) ayırt etmeksizin etiketleriyle toplar.\n",
        "    for char_dir in language_info.get(lang_code, []):\n",
        "        char_path = os.path.join(lang_path, char_dir)\n",
        "        if os.path.isdir(char_path):\n",
        "            label = char_dir\n",
        "            for img_name in os.listdir(char_path):\n",
        "                img_path = os.path.join(char_path, img_name)\n",
        "                if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    all_image_paths.append(img_path)\n",
        "                    all_labels.append(label)\n",
        "\n",
        "    print(f\"\\nVeri Kontrolü: '{lang_code}' için Toplam {len(all_labels)} resim bulundu.\")\n",
        "    if len(all_labels) == 0:\n",
        "        print(f\"Hata: '{lang_code}' dizininde hiç resim bulunamadı. Atlanıyor.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    encoded_labels = le.fit_transform(all_labels)\n",
        "\n",
        "    # Veri setini eğitim ve test olarak bölme\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "        all_image_paths, encoded_labels, test_size=test_size, random_state=random_state, stratify=encoded_labels\n",
        "    )\n",
        "\n",
        "    # Sınıf haritasını oluştur ve kaydet\n",
        "    class_map = {name: int(label) for name, label in zip(le.classes_, le.transform(le.classes_))}\n",
        "    class_map_path = os.path.join(DRIVE_MODEL_DIR, f'class_map_{lang_code}.json')\n",
        "    os.makedirs(os.path.dirname(class_map_path), exist_ok=True)\n",
        "    try:\n",
        "        with open(class_map_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(class_map, f, ensure_ascii=False, indent=4)\n",
        "            print(f\"\\n{lang_code} için {len(class_map)} sınıf haritası '{class_map_path}' dosyasına kaydedildi.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Uyarı: Sınıf haritası kaydedilemedi: {e}\")\n",
        "\n",
        "\n",
        "    return train_paths, test_paths, train_labels, test_labels, le.classes_\n",
        "\n",
        "# Veri zenginleştirme (Data Augmentation) ve normalizasyon adımları\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Doğrulama/Test için kullanılan transform\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# --- MODEL DEĞERLENDİRME ---\n",
        "\n",
        "def evaluate_model(model, test_loader, device, class_names):\n",
        "    \"\"\"Verilen modelin test verisi üzerindeki performansını değerlendirir.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    test_bar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# --- TEK DİL EĞİTİM FONKSİYONU ---\n",
        "\n",
        "def train_single_language_model(lang_code, train_paths, test_paths, train_labels, test_labels, class_names):\n",
        "    \"\"\"Tek bir dil için modeli eğitir, kaydeder ve raporlar.\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*20} {lang_code} DİLİ İÇİN EĞİTİM BAŞLIYOR ({len(class_names)} Sınıf) {'='*20}\")\n",
        "\n",
        "    epoch_log_path = os.path.join(DRIVE_MODEL_DIR, f'vmamba_{lang_code}_epoch_details.txt')\n",
        "\n",
        "    train_dataset = SignLanguageDataset(train_paths, train_labels, transform)\n",
        "    test_dataset = SignLanguageDataset(test_paths, test_labels, val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    num_classes = len(class_names)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = CustomMambaClassifier(num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Log dosyası için başlık yazma\n",
        "    with open(epoch_log_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"--- VMAMBA EĞİTİM DETAYLI EPOCH LOGLARI ({lang_code}) ---\\n\")\n",
        "        f.write(f\"Başlangıç Tarih/Saat: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Veri Seti Boyutu (Eğitim): {len(train_dataset)}, (Test): {len(test_dataset)}\\n\")\n",
        "        f.write(f\"Toplam Sınıf Sayısı: {num_classes}\\n\")\n",
        "        f.write(\"-\" * 50 + \"\\n\\n\")\n",
        "\n",
        "\n",
        "    # --- EĞİTİM DÖNGÜSÜ (COLAB'DA UZUN SÜRE BİLİR!) ---\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        epoch_start_datetime = datetime.now().strftime(\"%H:%M:%S\")\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [{lang_code} Eğitimi]\", leave=False)\n",
        "        for images, labels in train_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            train_bar.set_postfix({'Kayıp': running_loss / (train_bar.n + 1)})\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # --- EPOCH SONU DEĞERLENDİRME ---\n",
        "\n",
        "        overall_accuracy, overall_report = evaluate_model(model, test_loader, device, class_names)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_end_datetime = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "\n",
        "        # Süreyi HH saat, MM dakika, SS saniye formatına dönüştür\n",
        "        formatted_epoch_duration = format_duration(epoch_duration)\n",
        "\n",
        "        # --- MODEL VE LOG KAYDETME ---\n",
        "\n",
        "        # 1. Modeli kaydet (pth)\n",
        "        model_filename = f'vmamba_{lang_code}_epoch_{epoch+1}.pth'\n",
        "        model_path = os.path.join(DRIVE_MODEL_DIR, model_filename)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"\\nModel, '{model_path}' olarak kaydedildi.\")\n",
        "\n",
        "        # 2. Detaylı Epoch Raporunu kaydet (txt)\n",
        "        with open(epoch_log_path, 'a', encoding='utf-8') as f:\n",
        "            f.write(f\"| --- EPOCH {epoch+1}/{NUM_EPOCHS} Raporu ({lang_code}) ---\\n\")\n",
        "            f.write(f\"| Başlangıç Saati: {epoch_start_datetime}\\n\")\n",
        "            f.write(f\"| Bitiş Saati: {epoch_end_datetime}\\n\")\n",
        "            f.write(f\"| Süre: {formatted_epoch_duration}\\n\") # İSTENEN FORMAT\n",
        "            f.write(f\"| Ortalama Eğitim Kaybı: {avg_train_loss:.4f}\\n\")\n",
        "            f.write(f\"| Test Doğruluğu: {overall_accuracy:.4f}\\n\")\n",
        "            f.write(\"| Sınıflandırma Raporu:\\n\")\n",
        "\n",
        "            for line in overall_report.split('\\n'):\n",
        "                 f.write(f\"| {line.strip()}\\n\")\n",
        "\n",
        "            f.write(\"| ------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1} tamamlandı. Doğruluk: {overall_accuracy:.4f}. Detaylı rapor '{epoch_log_path}' dosyasına eklendi.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "\n",
        "    # --- DİL BAZLI BİTİŞ RAPORU ---\n",
        "    print(f\"\\n{lang_code} DİLİ EĞİTİMİ BAŞARIYLA TAMAMLANDI.\")\n",
        "    print(f\"Son Model: {model_path}\")\n",
        "\n",
        "\n",
        "# --- ANA EĞİTİM BORU HATTI ---\n",
        "\n",
        "def run_training_pipeline():\n",
        "    \"\"\"SADECE TR dili için eğitim sürecini yönetir.\"\"\"\n",
        "\n",
        "    global_start_time = time.time()\n",
        "    os.makedirs(DRIVE_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Kullanılan Cihaz: {device}\")\n",
        "\n",
        "    all_language_stats = {}\n",
        "\n",
        "    # Sadece TR için eğitim başlatılıyor\n",
        "    for lang_code in ALL_LANG_CODES:\n",
        "        lang_start_time = time.time()\n",
        "\n",
        "        train_paths, test_paths, train_labels, test_labels, class_names = prepare_lang_data(ROOT_DIR, lang_code)\n",
        "\n",
        "        if train_paths is None:\n",
        "            continue\n",
        "\n",
        "        train_single_language_model(lang_code, train_paths, test_paths, train_labels, test_labels, class_names)\n",
        "\n",
        "        lang_duration = time.time() - lang_start_time\n",
        "        all_language_stats[lang_code] = format_duration(lang_duration)\n",
        "\n",
        "        print(f\"\\n--- {lang_code} İşlemleri Tamamlandı. Toplam Süre: {all_language_stats[lang_code]} ---\\n\")\n",
        "\n",
        "\n",
        "    # --- GLOBAL BİTİŞ RAPORU ---\n",
        "    global_duration = time.time() - global_start_time\n",
        "    formatted_global_duration = format_duration(global_duration)\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"TÜRKÇE DİL MODELİNİN EĞİTİMİ BAŞARIYLA TAMAMLANDI.\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Tüm Eğitim Süresi: {formatted_global_duration}\")\n",
        "\n",
        "# Eğitimi başlat\n",
        "if __name__ == '__main__':\n",
        "    run_training_pipeline()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "0c74e7f2ba9345de8d2e4a235edeffbb",
            "bee8db59800840d3a82c94ea0f8f5ab9",
            "003690d14a944274a8f345f22a82a774",
            "e6dd645e4ee34f61b32c87c738bbd73e",
            "fbd1ed5fab344825862d66164d615104",
            "aec8464febb04c4f98540f3ef8f902a8",
            "1256e58c8cc74deebc86a47d91799680",
            "cafb0ac332714a52881c8bc2c71785fc",
            "e8a590c25df74af6b307f53a56b40da7",
            "f5b9820830f64da48c94ad6a4f74d510",
            "f6ac8f52bf4d46adb85a37e8ccc27277"
          ]
        },
        "id": "xYqgDZsehP9B",
        "outputId": "635fe4ce-9260-4fbe-b059-fb1169b5285d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kullanılan Cihaz: cuda\n",
            "\n",
            "Veri Kontrolü: 'TR' için Toplam 34500 resim bulundu.\n",
            "\n",
            "TR için 23 sınıf haritası '/content/drive/MyDrive/vmamba_models/class_map_TR.json' dosyasına kaydedildi.\n",
            "\n",
            "==================== TR DİLİ İÇİN EĞİTİM BAŞLIYOR (23 Sınıf) ====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c74e7f2ba9345de8d2e4a235edeffbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model, '/content/drive/MyDrive/vmamba_models/vmamba_TR_epoch_1.pth' olarak kaydedildi.\n",
            "Epoch 1 tamamlandı. Doğruluk: 0.9967. Detaylı rapor '/content/drive/MyDrive/vmamba_models/vmamba_TR_epoch_details.txt' dosyasına eklendi.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model, '/content/drive/MyDrive/vmamba_models/vmamba_TR_epoch_2.pth' olarak kaydedildi.\n",
            "Epoch 2 tamamlandı. Doğruluk: 0.9907. Detaylı rapor '/content/drive/MyDrive/vmamba_models/vmamba_TR_epoch_details.txt' dosyasına eklendi.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model, '/content/drive/MyDrive/vmamba_models/vmamba_TR_epoch_3.pth' olarak kaydedildi.\n",
            "Epoch 3 tamamlandı. Doğruluk: 0.9784. Detaylı rapor '/content/drive/MyDrive/vmamba_models/vmamba_TR_epoch_details.txt' dosyasına eklendi.\n",
            "--------------------------------------------------\n",
            "\n",
            "TR DİLİ EĞİTİMİ BAŞARIYLA TAMAMLANDI.\n",
            "Son Model: /content/drive/MyDrive/vmamba_models/vmamba_TR_epoch_3.pth\n",
            "\n",
            "--- TR İşlemleri Tamamlandı. Toplam Süre: 04 saat, 27 dakika, 03 saniye ---\n",
            "\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TÜRKÇE DİL MODELİNİN EĞİTİMİ BAŞARIYLA TAMAMLANDI.\n",
            "======================================================================\n",
            "Tüm Eğitim Süresi: 04 saat, 27 dakika, 03 saniye\n"
          ]
        }
      ]
    }
  ]
}