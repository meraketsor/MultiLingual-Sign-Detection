{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5hceM64sqyI",
        "outputId": "a0669ac6-4b3d-4482-eb0a-61346c641f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm scikit-learn numpy pandas tqdm torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Bu k\u0131s\u0131m sadece Colab'da \u00e7al\u0131\u015f\u0131r\n",
        "try:\n",
        "    print(\"Google Drive'a ba\u011flan\u0131l\u0131yor...\")\n",
        "    # Colab'da kimlik do\u011frulama penceresi a\u00e7\u0131l\u0131r\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Drive ba\u011flant\u0131s\u0131 ba\u015far\u0131l\u0131.\")\n",
        "\n",
        "    # Veri setinizin Google Drive'daki ana yolu (EN, AR, TR alt klas\u00f6rlerini i\u00e7erir)\n",
        "    # L\u00fctfen Drive'daki yolu kontrol edin ve gerekirse g\u00fcncelleyin.\n",
        "    DATA_DIR = '/content/drive/MyDrive/data_v1'\n",
        "\n",
        "except Exception as e:\n",
        "    # Hata durumunda veya Colab d\u0131\u015f\u0131nda \u00e7al\u0131\u015f\u0131yorsa\n",
        "    print(f\"Drive ba\u011flant\u0131 hatas\u0131 veya Colab ortam\u0131 alg\u0131lanmad\u0131: {e}\")\n",
        "    DATA_DIR = './data_v1' # Yerel denemeler i\u00e7in yedek yol\n",
        "\n",
        "# Veri klas\u00f6r\u00fcn\u00fcn varl\u0131\u011f\u0131n\u0131 kontrol et\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    # Bu, kullan\u0131c\u0131ya Drive ba\u011flant\u0131s\u0131n\u0131n ba\u015far\u0131l\u0131 olsa bile veri yolunun yanl\u0131\u015f oldu\u011funu bildirir\n",
        "    raise FileNotFoundError(f\"Hata: '{DATA_DIR}' yolu bulunamad\u0131. L\u00fctfen Google Drive'daki veri klas\u00f6r\u00fcn\u00fcn do\u011fru konumda oldu\u011fundan emin olun.\")\n",
        "else:\n",
        "    print(f\"Veri klas\u00f6r\u00fc ba\u015far\u0131yla bulundu: {DATA_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Pt2_g0tBxI",
        "outputId": "838b5780-5bb3-4356-8741-0ef145d7288d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive'a ba\u011flan\u0131l\u0131yor...\n",
            "Mounted at /content/drive\n",
            "Drive ba\u011flant\u0131s\u0131 ba\u015far\u0131l\u0131.\n",
            "Veri klas\u00f6r\u00fc ba\u015far\u0131yla bulundu: /content/drive/MyDrive/data_v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# --- YARDIMCI FONKS\u0130YON: S\u00dcRE FORMATLAMA ---\n",
        "\n",
        "def format_duration(seconds):\n",
        "    \"\"\"Saniye cinsinden s\u00fcreyi (H saat, M dakika, S saniye) format\u0131na d\u00f6n\u00fc\u015ft\u00fcr\u00fcr.\"\"\"\n",
        "    seconds = int(round(seconds))\n",
        "    h = seconds // 3600\n",
        "    m = (seconds % 3600) // 60\n",
        "    s = seconds % 60\n",
        "    return f\"{h:02d} saat, {m:02d} dakika, {s:02d} saniye\"\n",
        "\n",
        "# --- YAPILANDIRMA VE YOL TANIMLARI ---\n",
        "\n",
        "# L\u00dcTFEN KONTROL ED\u0130N: Drive \u00fczerindeki verilerinizin ana klas\u00f6r yolu\n",
        "ROOT_DIR = '/content/drive/MyDrive/data_v1'\n",
        "# E\u011e\u0130T\u0130LM\u0130\u015e MODELLER\u0130N KAYDED\u0130LECE\u011e\u0130 KLAS\u00d6R YOLU (Swin yerine ConvNeXt olarak g\u00fcncellendi)\n",
        "DRIVE_MODEL_DIR = '/content/drive/MyDrive/convnext_image_models_colab'\n",
        "\n",
        "# ConvNeXt Model Mimarisi (Swin yerine ConvNeXt Tiny se\u00e7ildi)\n",
        "CONVNEXT_MODEL_NAME = 'convnext_tiny' # \u0130stenirse 'convnext_base', 'convnext_large' vb. ile de\u011fi\u015ftirilebilir.\n",
        "\n",
        "# Dil ve S\u0131n\u0131f Yap\u0131land\u0131rmalar\u0131: Bu harita, hangi dil klas\u00f6r\u00fcnde hangi alt klas\u00f6rlerin (s\u0131n\u0131flar\u0131n) aranaca\u011f\u0131n\u0131 belirler.\n",
        "language_info = {\n",
        "    # TR: Kullan\u0131c\u0131n\u0131n verdi\u011fi TSL s\u0131n\u0131f listesi\n",
        "    'TR': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z'],\n",
        "    # AR: Kullan\u0131c\u0131n\u0131n \u00f6nceki dosyas\u0131ndaki Arap alfabesi i\u015faretleri\n",
        "    'AR': ['ain', 'al', 'aleff', 'bb', 'dal', 'dha', 'dhad', 'fa', 'gaaf', 'ghain', 'ha', 'haa', 'jeem', 'kaaf', 'khaa', 'la', 'laam', 'meem', 'nun', 'ra', 'saad', 'seen', 'sheen', 'taa', 'taad', 'tha', 'tah', 'ya', 'yaa', 'zay', 'zal'],\n",
        "    # EN: Standart 26 ASL harfi\n",
        "    'EN': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'],\n",
        "}\n",
        "ALL_LANG_CODES = ['EN', 'AR', 'TR'] # T\u00fcm diller i\u00e7in e\u011fitim yap\u0131lacak\n",
        "\n",
        "# E\u011fitim parametreleri\n",
        "NUM_EPOCHS = 50         # Colab GPU i\u00e7in varsay\u0131lan olarak korundu\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0001\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- MODEL TANIMLAMA (ConvNeXt i\u00e7in g\u00fcncellendi) ---\n",
        "\n",
        "def create_model(num_classes, pretrained=True):\n",
        "    \"\"\"ConvNeXt modelini Timm kullanarak tan\u0131mlar ve a\u011f\u0131rl\u0131klar\u0131 y\u00fckler.\"\"\"\n",
        "    print(f\"Timm K\u00fct\u00fcphanesinden {CONVNEXT_MODEL_NAME} Y\u00fckleniyor...\")\n",
        "\n",
        "    # Pretrained=True ile ImageNet a\u011f\u0131rl\u0131klar\u0131n\u0131 y\u00fckle\n",
        "    # ConvNeXt, modern bir CNN mimarisidir ve timm'de desteklenir.\n",
        "    model = timm.create_model(CONVNEXT_MODEL_NAME, pretrained=pretrained, num_classes=num_classes)\n",
        "\n",
        "    # \u00c7\u0131k\u0131\u015f katman\u0131 (classifier) otomatik olarak num_classes'e ayarlanm\u0131\u015ft\u0131r.\n",
        "    return model\n",
        "\n",
        "\n",
        "class SignLanguageDataset(Dataset):\n",
        "    \"\"\"\u0130\u015faret dili g\u00f6r\u00fcnt\u00fcleri i\u00e7in \u00f6zel veri k\u00fcmesi s\u0131n\u0131f\u0131.\"\"\"\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            # G\u00f6r\u00fcnt\u00fcy\u00fc a\u00e7 ve RGB format\u0131na \u00e7evir (Hata durumunda PIL'den kaynaklanabilir)\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            # Hatal\u0131/bozuk resimleri raporla ve atla (d\u00f6ng\u00fcy\u00fc bozmamak i\u00e7in)\n",
        "            print(f\"Uyar\u0131: Resim y\u00fcklenemedi {img_path}: {e}\")\n",
        "            # Bu durumun DataLoader'da hata vermesine neden olabilece\u011fini unutmay\u0131n,\n",
        "            # ancak bu kodu basitle\u015ftirilmi\u015f haliyle koruyoruz.\n",
        "            raise e\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# --- VER\u0130 HAZIRLAMA FONKS\u0130YONU ---\n",
        "\n",
        "def prepare_lang_data(root_dir, lang_code, test_size=TEST_SIZE, random_state=RANDOM_STATE):\n",
        "    \"\"\"Sadece belirtilen dilin resimlerini toplar ve etiketler.\"\"\"\n",
        "    all_image_paths = []\n",
        "    all_labels = []\n",
        "\n",
        "    lang_path = os.path.join(root_dir, lang_code)\n",
        "    class_list = language_info.get(lang_code, [])\n",
        "\n",
        "    if not os.path.exists(lang_path) or not class_list:\n",
        "        print(f\"Uyar\u0131: '{lang_code}' diline ait klas\u00f6r ({lang_path}) veya s\u0131n\u0131f bilgisi bulunamad\u0131. Bu dil atlan\u0131yor.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    # language_info'da tan\u0131mlanan her bir s\u0131n\u0131f (alt klas\u00f6r) i\u00e7in resimleri topla\n",
        "    for char_dir in class_list:\n",
        "        char_path = os.path.join(lang_path, char_dir)\n",
        "        if os.path.isdir(char_path):\n",
        "            label = char_dir\n",
        "            for img_name in os.listdir(char_path):\n",
        "                img_path = os.path.join(char_path, img_name)\n",
        "                # Resim dosyalar\u0131n\u0131 kontrol et (k\u00fc\u00e7\u00fck/b\u00fcy\u00fck harf duyars\u0131z)\n",
        "                if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    all_image_paths.append(img_path)\n",
        "                    all_labels.append(label)\n",
        "        else:\n",
        "            print(f\"Uyar\u0131: '{lang_code}' - '{char_dir}' s\u0131n\u0131f klas\u00f6r\u00fc bulunamad\u0131.\")\n",
        "\n",
        "    print(f\"\\nVeri Kontrol\u00fc: '{lang_code}' i\u00e7in Toplam {len(all_labels)} resim bulundu.\")\n",
        "    if len(all_labels) == 0:\n",
        "        print(f\"Hata: '{lang_code}' dizininde hi\u00e7 resim bulunamad\u0131. Atlan\u0131yor.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    # S\u0131n\u0131flar\u0131 say\u0131sal etiketlere d\u00f6n\u00fc\u015ft\u00fcr\n",
        "    le = LabelEncoder()\n",
        "    encoded_labels = le.fit_transform(all_labels)\n",
        "\n",
        "    # Veri setini e\u011fitim ve test olarak b\u00f6lme (stratify ile s\u0131n\u0131f da\u011f\u0131l\u0131m\u0131n\u0131 korur)\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "        all_image_paths, encoded_labels, test_size=test_size, random_state=random_state, stratify=encoded_labels\n",
        "    )\n",
        "\n",
        "    # S\u0131n\u0131f haritas\u0131n\u0131 olu\u015ftur ve kaydet\n",
        "    class_map = {name: int(label) for label, name in enumerate(le.classes_)} # {index: class_name}\n",
        "    # Dosya yolu ConvNeXt i\u00e7in g\u00fcncellendi\n",
        "    class_map_path = os.path.join(DRIVE_MODEL_DIR, f'class_map_{lang_code}.json')\n",
        "    os.makedirs(os.path.dirname(class_map_path), exist_ok=True)\n",
        "    try:\n",
        "        with open(class_map_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(class_map, f, ensure_ascii=False, indent=4)\n",
        "            print(f\"\\n{lang_code} i\u00e7in {len(class_map)} s\u0131n\u0131f haritas\u0131 '{class_map_path}' dosyas\u0131na kaydedildi.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Uyar\u0131: S\u0131n\u0131f haritas\u0131 kaydedilemedi: {e}\")\n",
        "\n",
        "\n",
        "    return train_paths, test_paths, train_labels, test_labels, le.classes_\n",
        "\n",
        "# Veri zenginle\u015ftirme (Data Augmentation) ve normalizasyon ad\u0131mlar\u0131 (ConvNeXt i\u00e7in standart)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    # ConvNeXt/ImageNet i\u00e7in standart normalizasyon de\u011ferleri\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Do\u011frulama/Test i\u00e7in kullan\u0131lan transform (Sadece yeniden boyutland\u0131rma ve normalizasyon)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# --- MODEL DE\u011eERLEND\u0130RME ---\n",
        "\n",
        "def evaluate_model(model, test_loader, device, class_names):\n",
        "    \"\"\"Verilen modelin test verisi \u00fczerindeki performans\u0131n\u0131 de\u011ferlendirir.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Test/De\u011ferlendirme d\u00f6ng\u00fcs\u00fcnde tqdm'i kullanmak g\u00f6rsel geri bildirim i\u00e7in iyidir.\n",
        "    test_bar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    # Raporu olu\u015ftururken s\u0131n\u0131f isimlerini kullan\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0, digits=4)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# --- TEK D\u0130L E\u011e\u0130T\u0130M FONKS\u0130YONU ---\n",
        "\n",
        "def train_single_language_model(lang_code, train_paths, test_paths, train_labels, test_labels, class_names):\n",
        "    \"\"\"Tek bir dil i\u00e7in modeli e\u011fitir, kaydeder ve raporlar.\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*20} {lang_code} D\u0130L\u0130 \u0130\u00c7\u0130N E\u011e\u0130T\u0130M BA\u015eLIYOR ({len(class_names)} S\u0131n\u0131f) {'='*20}\")\n",
        "\n",
        "    # Log dosyas\u0131n\u0131n yolu (ConvNeXt i\u00e7in g\u00fcncellendi)\n",
        "    epoch_log_path = os.path.join(DRIVE_MODEL_DIR, f'convnext_{lang_code}_epoch_details.txt')\n",
        "\n",
        "    # DataLoader'lar\u0131 olu\u015ftur\n",
        "    train_dataset = SignLanguageDataset(train_paths, train_labels, transform)\n",
        "    test_dataset = SignLanguageDataset(test_paths, test_labels, val_transform)\n",
        "\n",
        "    # Colab'da GPU kullan\u0131rken num_workers'\u0131 art\u0131rmak veri y\u00fckleme h\u0131z\u0131n\u0131 art\u0131r\u0131r\n",
        "    num_workers_to_use = 4 if torch.cuda.is_available() else 0\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers_to_use)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers_to_use)\n",
        "\n",
        "    num_classes = len(class_names)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # ConvNeXt Modeli Olu\u015ftur (fonksiyon ad\u0131 g\u00fcncellendi)\n",
        "    model = create_model(num_classes).to(device)\n",
        "\n",
        "    # Optimizasyon ve Kay\u0131p Fonksiyonu\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE) # ConvNeXt i\u00e7in de AdamW yayg\u0131nd\u0131r\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Log dosyas\u0131 i\u00e7in ba\u015fl\u0131k yazma (ConvNeXt i\u00e7in g\u00fcncellendi)\n",
        "    with open(epoch_log_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"--- CONVNEXT E\u011e\u0130T\u0130M DETAYLI EPOCH LOGLARI ({lang_code}) ---\\n\")\n",
        "        f.write(f\"Model: {CONVNEXT_MODEL_NAME}, Epochs: {NUM_EPOCHS}, LR: {LEARNING_RATE}\\n\")\n",
        "        f.write(f\"Kullan\u0131lan Cihaz: {device}\\n\")\n",
        "        f.write(f\"Ba\u015flang\u0131\u00e7 Tarih/Saat: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Veri Seti Boyutu (E\u011fitim): {len(train_dataset)}, (Test): {len(test_dataset)}\\n\")\n",
        "        f.write(f\"Toplam S\u0131n\u0131f Say\u0131s\u0131: {num_classes}\\n\")\n",
        "        f.write(\"-\" * 70 + \"\\n\\n\")\n",
        "\n",
        "\n",
        "    # --- E\u011e\u0130T\u0130M D\u00d6NG\u00dcS\u00dc ---\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        epoch_start_datetime = datetime.now().strftime(\"%H:%M:%S\")\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [{lang_code} E\u011fitimi]\", leave=False)\n",
        "        for images, labels in train_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            train_bar.set_postfix({'Kay\u0131p': f'{running_loss / (train_bar.n + 1):.4f}'})\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # --- EPOCH SONU DE\u011eERLEND\u0130RME ---\n",
        "\n",
        "        # evaluate_model, Test do\u011frulu\u011funu ve s\u0131n\u0131fland\u0131rma raporunu d\u00f6nd\u00fcr\u00fcr\n",
        "        overall_accuracy, overall_report = evaluate_model(model, test_loader, device, class_names)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_end_datetime = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "\n",
        "        # S\u00fcreyi HH saat, MM dakika, SS saniye format\u0131na d\u00f6n\u00fc\u015ft\u00fcr\n",
        "        formatted_epoch_duration = format_duration(epoch_duration)\n",
        "\n",
        "        # Ekrana \u00d6zet Rapor Yazd\u0131r\n",
        "        print(f\"\\n|--- EPOCH {epoch+1}/{NUM_EPOCHS} Raporu ({lang_code}) ---\")\n",
        "        print(f\"| S\u00fcre: {formatted_epoch_duration} | E\u011ft. Kayb\u0131: {avg_train_loss:.4f} | Test Do\u011frulu\u011fu: {overall_accuracy:.4f}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "\n",
        "        # --- MODEL VE LOG KAYDETME ---\n",
        "\n",
        "        # 1. Modeli kaydet (pth) - ConvNeXt i\u00e7in g\u00fcncellendi\n",
        "        model_filename = f'convnext_{lang_code}_epoch_{epoch+1}.pth'\n",
        "        model_path = os.path.join(DRIVE_MODEL_DIR, model_filename)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        # 2. Detayl\u0131 Epoch Raporunu kaydet (txt)\n",
        "        with open(epoch_log_path, 'a', encoding='utf-8') as f:\n",
        "            f.write(f\"| --- EPOCH {epoch+1}/{NUM_EPOCHS} Raporu ({lang_code}) ---\\n\")\n",
        "            f.write(f\"| Ba\u015flang\u0131\u00e7 Saati: {epoch_start_datetime}\\n\")\n",
        "            f.write(f\"| Biti\u015f Saati: {epoch_end_datetime}\\n\")\n",
        "            f.write(f\"| S\u00fcre: {formatted_epoch_duration}\\n\") # \u0130STENEN FORMAT\n",
        "            f.write(f\"| Ortalama E\u011fitim Kayb\u0131: {avg_train_loss:.4f}\\n\")\n",
        "            f.write(f\"| Test Do\u011frulu\u011fu: {overall_accuracy:.4f}\\n\")\n",
        "            f.write(\"| S\u0131n\u0131fland\u0131rma Raporu:\\n\")\n",
        "\n",
        "            # Classification Report \u00e7\u0131kt\u0131s\u0131n\u0131 sat\u0131r sat\u0131r log dosyas\u0131na yaz\n",
        "            for line in overall_report.split('\\n'):\n",
        "                f.write(f\"| {line}\\n\")\n",
        "\n",
        "            f.write(\"| ------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "        print(f\"Model, '{model_path}' olarak kaydedildi.\")\n",
        "        print(f\"Detayl\u0131 rapor '{epoch_log_path}' dosyas\u0131na eklendi.\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "\n",
        "    # --- D\u0130L BAZLI B\u0130T\u0130\u015e RAPORU ---\n",
        "    print(f\"\\n{lang_code} D\u0130L\u0130 E\u011e\u0130T\u0130M\u0130 BA\u015eARIYLA TAMAMLANDI.\")\n",
        "    print(f\"Son Model: {model_path}\")\n",
        "\n",
        "\n",
        "# --- ANA E\u011e\u0130T\u0130M BORU HATTI ---\n",
        "\n",
        "def run_training_pipeline():\n",
        "    \"\"\"T\u00fcm tan\u0131ml\u0131 diller i\u00e7in e\u011fitim s\u00fcrecini y\u00f6netir.\"\"\"\n",
        "\n",
        "    global_start_time = time.time()\n",
        "    os.makedirs(DRIVE_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if device.type == 'cuda':\n",
        "        print(f\"Kullan\u0131lan Cihaz: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(f\"UYARI: Sadece CPU/RAM mevcut. E\u011fitim \u00e7ok uzun s\u00fcrecektir. Colab'da GPU'yu etkinle\u015ftirin. Kullan\u0131lan Cihaz: {device}\")\n",
        "\n",
        "    all_language_stats = {}\n",
        "\n",
        "    # T\u00fcm diller i\u00e7in e\u011fitim ba\u015flat\u0131l\u0131yor\n",
        "    for lang_code in ALL_LANG_CODES:\n",
        "        lang_start_time = time.time()\n",
        "\n",
        "        # Veri Haz\u0131rlama\n",
        "        train_paths, test_paths, train_labels, test_labels, class_names = prepare_lang_data(ROOT_DIR, lang_code)\n",
        "\n",
        "        if train_paths is None:\n",
        "            continue\n",
        "\n",
        "        # Modeli E\u011fitme\n",
        "        train_single_language_model(lang_code, train_paths, test_paths, train_labels, test_labels, class_names)\n",
        "\n",
        "        lang_duration = time.time() - lang_start_time\n",
        "        all_language_stats[lang_code] = format_duration(lang_duration)\n",
        "\n",
        "        print(f\"\\n--- {lang_code} \u0130\u015flemleri Tamamland\u0131. Toplam S\u00fcre: {all_language_stats[lang_code]} ---\\n\")\n",
        "\n",
        "\n",
        "    # --- GLOBAL B\u0130T\u0130\u015e RAPORU ---\n",
        "    global_duration = time.time() - global_start_time\n",
        "    formatted_global_duration = format_duration(global_duration)\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"T\u00dcM D\u0130L MODELLER\u0130N\u0130N E\u011e\u0130T\u0130M\u0130 BA\u015eARIYLA TAMAMLANDI.\")\n",
        "    print(\"=\"*70)\n",
        "    for lang, duration in all_language_stats.items():\n",
        "        print(f\"- {lang} Dili Toplam E\u011fitim S\u00fcresi: {duration}\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"T\u00fcm Projenin Toplam S\u00fcresi: {formatted_global_duration}\")\n",
        "\n",
        "# E\u011fitimi ba\u015flat\n",
        "if __name__ == '__main__':\n",
        "    run_training_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616,
          "referenced_widgets": [
            "49a0df6e82a64653b1e4b651762cb6ab",
            "eb0bd04aa58e4557acad292cc9fcda5f",
            "fe3664614e0e4587afb03b511d2ecde6",
            "fe877b0e73024c489b7fee903df876d6",
            "b714b62fec8d4b4bb9030a18da62db4d",
            "b79da4f715a041e6a58d5450b1e70a22",
            "d2146526e14f47e090012f44733ffab7",
            "b1480e0ba00e4fcebed9d274895dd458",
            "35791ea324f4417f8ab59b77da31437e",
            "4a2307fa5deb407395a2d525935a4496",
            "634d2f15d8cc4e4f8bbb31c067bf53ef"
          ]
        },
        "id": "kfcwHckJtTi8",
        "outputId": "db3b1825-e6f8-40bd-a49a-100c9fde3e71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kullan\u0131lan Cihaz: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "Veri Kontrol\u00fc: 'EN' i\u00e7in Toplam 39000 resim bulundu.\n",
            "\n",
            "EN i\u00e7in 26 s\u0131n\u0131f haritas\u0131 '/content/drive/MyDrive/convnext_image_models_colab/class_map_EN.json' dosyas\u0131na kaydedildi.\n",
            "\n",
            "==================== EN D\u0130L\u0130 \u0130\u00c7\u0130N E\u011e\u0130T\u0130M BA\u015eLIYOR (26 S\u0131n\u0131f) ====================\n",
            "Timm K\u00fct\u00fcphanesinden convnext_tiny Y\u00fckleniyor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49a0df6e82a64653b1e4b651762cb6ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3544109742.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;31m# E\u011fitimi ba\u015flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mrun_training_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3544109742.py\u001b[0m in \u001b[0;36mrun_training_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# Modeli E\u011fitme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mtrain_single_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mlang_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlang_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3544109742.py\u001b[0m in \u001b[0;36mtrain_single_language_model\u001b[0;34m(lang_code, train_paths, test_paths, train_labels, test_labels, class_names)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;34m\"\"\"Forward pass.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;34m\"\"\"Forward pass through feature extraction layers.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;34m\"\"\"Forward pass.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_conv_mlp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}